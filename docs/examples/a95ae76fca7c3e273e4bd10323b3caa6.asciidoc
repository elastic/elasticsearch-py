// This file is autogenerated, DO NOT EDIT
// tab-widgets/inference-api/infer-api-ingest-pipeline.asciidoc:119

[source, python]
----
resp = client.ingest.put_pipeline(
    id="azure_openai_embeddings_pipeline",
    processors=[
        {
            "inference": {
                "model_id": "azure_openai_embeddings",
                "input_output": {
                    "input_field": "content",
                    "output_field": "content_embedding"
                }
            }
        }
    ],
)
print(resp)
----
