// This file is autogenerated, DO NOT EDIT
// inference/chat-completion-inference.asciidoc:305

[source, python]
----
resp = client.inference.stream_inference(
    task_type="chat_completion",
    inference_id="openai-completion",
    model="gpt-4o",
    messages=[
        {
            "role": "user",
            "content": "What is Elastic?"
        }
    ],
)
print(resp)
----
