// This file is autogenerated, DO NOT EDIT
// inference/chat-completion-inference.asciidoc:305

[source, python]
----
resp = client.inference.chat_completion_unified(
    inference_id="openai-completion",
    chat_completion_request={
        "model": "gpt-4o",
        "messages": [
            {
                "role": "user",
                "content": "What is Elastic?"
            }
        ]
    },
)
print(resp)
----
