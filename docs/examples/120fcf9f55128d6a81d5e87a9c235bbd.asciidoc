// This file is autogenerated, DO NOT EDIT
// inference/chat-completion-inference.asciidoc:301

[source, python]
----
resp = client.perform_request(
    "POST",
    "/_inference/chat_completion/openai-completion/_stream",
    headers={"Content-Type": "application/json"},
    body={
        "model": "gpt-4o",
        "messages": [
            {
                "role": "user",
                "content": "What is Elastic?"
            }
        ]
    },
)
print(resp)
----
