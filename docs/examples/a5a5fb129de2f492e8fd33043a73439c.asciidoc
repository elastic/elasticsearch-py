// This file is autogenerated, DO NOT EDIT
// analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc:152

[source, python]
----
resp = client.indices.create(
    index="dictionary_decompound_example",
    settings={
        "analysis": {
            "analyzer": {
                "standard_dictionary_decompound": {
                    "tokenizer": "standard",
                    "filter": [
                        "22_char_dictionary_decompound"
                    ]
                }
            },
            "filter": {
                "22_char_dictionary_decompound": {
                    "type": "dictionary_decompounder",
                    "word_list_path": "analysis/example_word_list.txt",
                    "max_subword_size": 22
                }
            }
        }
    },
)
print(resp)
----
