// This file is autogenerated, DO NOT EDIT
// analysis/tokenfilters/common-grams-tokenfilter.asciidoc:28

[source, python]
----
resp = client.indices.analyze(
    tokenizer="whitespace",
    filter=[
        {
            "type": "common_grams",
            "common_words": [
                "is",
                "the"
            ]
        }
    ],
    text="the quick fox is brown",
)
print(resp)
----
