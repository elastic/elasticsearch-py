// This file is autogenerated, DO NOT EDIT
// analysis/tokenfilters/word-delimiter-graph-tokenfilter.asciidoc:410

[source, python]
----
resp = client.indices.create(
    index="my-index-000001",
    settings={
        "analysis": {
            "analyzer": {
                "my_analyzer": {
                    "tokenizer": "keyword",
                    "filter": [
                        "my_custom_word_delimiter_graph_filter"
                    ]
                }
            },
            "filter": {
                "my_custom_word_delimiter_graph_filter": {
                    "type": "word_delimiter_graph",
                    "type_table": [
                        "- => ALPHA"
                    ],
                    "split_on_case_change": False,
                    "split_on_numerics": False,
                    "stem_english_possessive": True
                }
            }
        }
    },
)
print(resp)
----
