// This file is autogenerated, DO NOT EDIT
// inference/service-elasticsearch.asciidoc:264

[source, python]
----
resp = client.inference.put(
    task_type="text_embedding",
    inference_id="my-e5-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "adaptive_allocations": {
                "enabled": True,
                "min_number_of_allocations": 3,
                "max_number_of_allocations": 10
            },
            "num_threads": 1,
            "model_id": ".multilingual-e5-small"
        }
    },
)
print(resp)
----
