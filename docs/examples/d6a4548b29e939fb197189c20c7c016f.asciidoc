// This file is autogenerated, DO NOT EDIT
// inference/elastic-infer-service.asciidoc:115

[source, python]
----
resp = client.inference.put(
    task_type="chat_completion",
    inference_id="chat-completion-endpoint",
    inference_config={
        "service": "elastic",
        "service_settings": {
            "model_id": "model-1"
        }
    },
)
print(resp)
----
