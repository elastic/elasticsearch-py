// This file is autogenerated, DO NOT EDIT
// analysis/tokenfilters/shingle-tokenfilter.asciidoc:374

[source, python]
----
resp = client.indices.analyze(
    tokenizer="whitespace",
    filter=[
        {
            "type": "stop",
            "stopwords": [
                "a"
            ]
        },
        {
            "type": "shingle",
            "filler_token": "+"
        }
    ],
    text="fox jumps a lazy dog",
)
print(resp)
----
