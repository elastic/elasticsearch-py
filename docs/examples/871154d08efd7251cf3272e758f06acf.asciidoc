// This file is autogenerated, DO NOT EDIT
// analysis/tokenfilters/common-grams-tokenfilter.asciidoc:126

[source, python]
----
resp = client.indices.create(
    index="common_grams_example",
    settings={
        "analysis": {
            "analyzer": {
                "index_grams": {
                    "tokenizer": "whitespace",
                    "filter": [
                        "common_grams"
                    ]
                }
            },
            "filter": {
                "common_grams": {
                    "type": "common_grams",
                    "common_words": [
                        "a",
                        "is",
                        "the"
                    ]
                }
            }
        }
    },
)
print(resp)
----
