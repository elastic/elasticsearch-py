// This file is autogenerated, DO NOT EDIT
// inference/service-elasticsearch.asciidoc:204

[source, python]
----
resp = client.inference.put(
    task_type="text_embedding",
    inference_id="my-e5-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1,
            "model_id": ".multilingual-e5-small"
        }
    },
)
print(resp)
----
